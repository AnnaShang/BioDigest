{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
      "       'Bread_Paste_', 'Waste_oil_', 'Total_Waste_', 'Diesel_waste_water_',\n",
      "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_', 'acid_feed',\n",
      "       'acid_discharge', 'anaerobic_feed', 'anaerobic_cumuprod',\n",
      "       'anaerobic_dailyoutput'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Kitchen_waste_</th>\n",
       "      <th>Fruit_and_vegetable_waste_</th>\n",
       "      <th>Bread_Paste_</th>\n",
       "      <th>Waste_oil_</th>\n",
       "      <th>Total_Waste_</th>\n",
       "      <th>Diesel_waste_water_</th>\n",
       "      <th>Flour_and_waste_oil_</th>\n",
       "      <th>Kitchen_waste_paste_</th>\n",
       "      <th>acid_feed</th>\n",
       "      <th>acid_discharge</th>\n",
       "      <th>anaerobic_feed</th>\n",
       "      <th>anaerobic_cumuprod</th>\n",
       "      <th>anaerobic_dailyoutput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>92.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.95</td>\n",
       "      <td>13.54</td>\n",
       "      <td>99.98</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>340453.0</td>\n",
       "      <td>7919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.30</td>\n",
       "      <td>16.10</td>\n",
       "      <td>91.73</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>343154.0</td>\n",
       "      <td>2701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>81.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.35</td>\n",
       "      <td>6.60</td>\n",
       "      <td>90.19</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>353361.0</td>\n",
       "      <td>10207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>81.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>17.48</td>\n",
       "      <td>90.15</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>363943.0</td>\n",
       "      <td>10582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.40</td>\n",
       "      <td>12.47</td>\n",
       "      <td>46.26</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>372971.0</td>\n",
       "      <td>9028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>21.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.20</td>\n",
       "      <td>11.85</td>\n",
       "      <td>37.78</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>385089.0</td>\n",
       "      <td>9118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>89.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>12.14</td>\n",
       "      <td>99.08</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>392165.0</td>\n",
       "      <td>10076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>80.46</td>\n",
       "      <td>9.80</td>\n",
       "      <td>16.90</td>\n",
       "      <td>13.92</td>\n",
       "      <td>107.16</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>402285.0</td>\n",
       "      <td>9936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>77.20</td>\n",
       "      <td>10.40</td>\n",
       "      <td>5.60</td>\n",
       "      <td>10.69</td>\n",
       "      <td>93.20</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>412201.0</td>\n",
       "      <td>9916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>78.37</td>\n",
       "      <td>9.34</td>\n",
       "      <td>8.30</td>\n",
       "      <td>9.79</td>\n",
       "      <td>96.01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>419348.0</td>\n",
       "      <td>7147.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Kitchen_waste_  Fruit_and_vegetable_waste_  Bread_Paste_  \\\n",
       "0           0           92.03                        0.00          7.95   \n",
       "1           1           78.43                        0.00         13.30   \n",
       "2           2           81.84                        0.00          8.35   \n",
       "3           3           81.05                        0.00          9.10   \n",
       "4           4           36.86                        0.00          9.40   \n",
       "5           5           21.58                        0.00         16.20   \n",
       "6           6           89.98                        0.00          9.10   \n",
       "7           7           80.46                        9.80         16.90   \n",
       "8           8           77.20                       10.40          5.60   \n",
       "9           9           78.37                        9.34          8.30   \n",
       "\n",
       "   Waste_oil_  Total_Waste_  Diesel_waste_water_  Flour_and_waste_oil_  \\\n",
       "0       13.54         99.98                 54.0                  17.0   \n",
       "1       16.10         91.73                 36.0                   8.0   \n",
       "2        6.60         90.19                 22.0                  34.0   \n",
       "3       17.48         90.15                 22.0                  20.0   \n",
       "4       12.47         46.26                 44.0                  35.0   \n",
       "5       11.85         37.78                 22.0                  21.0   \n",
       "6       12.14         99.08                 30.0                  48.0   \n",
       "7       13.92        107.16                 29.0                  31.0   \n",
       "8       10.69         93.20                 22.0                  12.0   \n",
       "9        9.79         96.01                 25.0                  40.0   \n",
       "\n",
       "   Kitchen_waste_paste_  acid_feed  acid_discharge  anaerobic_feed  \\\n",
       "0                 167.0        0.0             0.0           130.0   \n",
       "1                 100.0        0.0             0.0           170.0   \n",
       "2                 120.0        0.0             0.0           150.0   \n",
       "3                  92.0        0.0             0.0           160.0   \n",
       "4                 122.0        0.0             0.0           160.0   \n",
       "5                   0.0        0.0             0.0           160.0   \n",
       "6                  96.0        0.0             0.0           160.0   \n",
       "7                 148.0        0.0             0.0           170.0   \n",
       "8                 114.0        0.0             0.0           160.0   \n",
       "9                 140.0        0.0             0.0           200.0   \n",
       "\n",
       "   anaerobic_cumuprod  anaerobic_dailyoutput  \n",
       "0            340453.0                 7919.0  \n",
       "1            343154.0                 2701.0  \n",
       "2            353361.0                10207.0  \n",
       "3            363943.0                10582.0  \n",
       "4            372971.0                 9028.0  \n",
       "5            385089.0                 9118.0  \n",
       "6            392165.0                10076.0  \n",
       "7            402285.0                 9936.0  \n",
       "8            412201.0                 9916.0  \n",
       "9            419348.0                 7147.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shenzhen = pd.read_csv(\"Shenzhen_useful.csv\")\n",
    "shenzhen['acid_feed'] = shenzhen['1_acidification_hydrolysis_tank_feed_'] \\\n",
    "                                             + shenzhen['2_acidification_hydrolysis_tank_feed_']\n",
    "shenzhen['acid_discharge']  = shenzhen['1_acidification_hydrolysis_tank_discharge_']\\\n",
    "                                             + shenzhen['2_acidification_hydrolysis_tank_discharge_']\n",
    "shenzhen['anaerobic_feed'] = shenzhen['1_Anaerobic_tank_slurry_feed_'] \\\n",
    "                                             + shenzhen['2_Anaerobic_tank_slurry_feed_']\n",
    "shenzhen['anaerobic_cumuprod'] = shenzhen['1_Anaerobic_tank_biogas_cumulative_production_'] \\\n",
    "                                             + shenzhen['2_anaerobic_tank_biogas_cumulative_production_']\n",
    "shenzhen['anaerobic_dailyoutput'] = shenzhen['1_anaerobic_tank_biogas_daily_output_'] \\\n",
    "                                             + shenzhen['2_anaerobic_tank_biogas_daily_output_']\n",
    "shenzhen = shenzhen.drop(['1_acidification_hydrolysis_tank_feed_','2_acidification_hydrolysis_tank_feed_',\\\n",
    "               '1_acidification_hydrolysis_tank_discharge_','2_acidification_hydrolysis_tank_discharge_',\\\n",
    "               '1_Anaerobic_tank_slurry_feed_','2_Anaerobic_tank_slurry_feed_',\\\n",
    "               '1_Anaerobic_tank_biogas_cumulative_production_','2_anaerobic_tank_biogas_cumulative_production_',\\\n",
    "               '1_anaerobic_tank_biogas_daily_output_','2_anaerobic_tank_biogas_daily_output_'],axis = 1)\n",
    "print(shenzhen.columns)\n",
    "shenzhen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data len: 364\n",
      "test data len: 92\n"
     ]
    }
   ],
   "source": [
    "# split train and test data\n",
    "shenzhen_train, shenzhen_test = train_test_split(shenzhen, test_size=0.2)\n",
    "print('train data len:',len(shenzhen_train))\n",
    "print('test data len:',len(shenzhen_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Toy Model Part1: Model for anaerobic_dailyoutput__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>anaerobic_dailyoutput</td> <th>  R-squared:         </th> <td>   0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                     <td>OLS</td>          <th>  Adj. R-squared:    </th> <td>   0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>Least Squares</td>     <th>  F-statistic:       </th> <td>   13.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>               <td>Fri, 02 Mar 2018</td>    <th>  Prob (F-statistic):</th> <td>9.20e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                   <td>04:00:49</td>        <th>  Log-Likelihood:    </th> <td> -3296.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>        <td>   364</td>         <th>  AIC:               </th> <td>   6606.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>            <td>   357</td>         <th>  BIC:               </th> <td>   6634.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                <td>     6</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>nonrobust</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td> 4921.9964</td> <td>  336.603</td> <td>   14.623</td> <td> 0.000</td> <td> 4260.023</td> <td> 5583.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kitchen_waste_</th>             <td>   17.3998</td> <td>    6.527</td> <td>    2.666</td> <td> 0.008</td> <td>    4.564</td> <td>   30.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit_and_vegetable_waste_</th> <td>   22.0420</td> <td>    7.097</td> <td>    3.106</td> <td> 0.002</td> <td>    8.085</td> <td>   35.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bread_Paste_</th>               <td>  -53.8670</td> <td>   13.602</td> <td>   -3.960</td> <td> 0.000</td> <td>  -80.617</td> <td>  -27.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total_Waste_</th>               <td>  -14.4252</td> <td>    6.041</td> <td>   -2.388</td> <td> 0.017</td> <td>  -26.305</td> <td>   -2.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel_waste_water_</th>        <td>   12.6611</td> <td>    5.962</td> <td>    2.123</td> <td> 0.034</td> <td>    0.935</td> <td>   24.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flour_and_waste_oil_</th>       <td>   16.7290</td> <td>    6.976</td> <td>    2.398</td> <td> 0.017</td> <td>    3.010</td> <td>   30.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kitchen_waste_paste_</th>       <td>    8.7311</td> <td>    2.769</td> <td>    3.153</td> <td> 0.002</td> <td>    3.285</td> <td>   14.177</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.183</td> <th>  Durbin-Watson:     </th> <td>   2.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.004</td> <th>  Jarque-Bera (JB):  </th> <td>  11.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.430</td> <th>  Prob(JB):          </th> <td> 0.00329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.125</td> <th>  Cond. No.          </th> <td>3.38e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              OLS Regression Results                             \n",
       "=================================================================================\n",
       "Dep. Variable:     anaerobic_dailyoutput   R-squared:                       0.184\n",
       "Model:                               OLS   Adj. R-squared:                  0.171\n",
       "Method:                    Least Squares   F-statistic:                     13.45\n",
       "Date:                   Fri, 02 Mar 2018   Prob (F-statistic):           9.20e-14\n",
       "Time:                           04:00:49   Log-Likelihood:                -3296.2\n",
       "No. Observations:                    364   AIC:                             6606.\n",
       "Df Residuals:                        357   BIC:                             6634.\n",
       "Df Model:                              6                                         \n",
       "Covariance Type:               nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                   4921.9964    336.603     14.623      0.000    4260.023    5583.969\n",
       "Kitchen_waste_                17.3998      6.527      2.666      0.008       4.564      30.235\n",
       "Fruit_and_vegetable_waste_    22.0420      7.097      3.106      0.002       8.085      35.999\n",
       "Bread_Paste_                 -53.8670     13.602     -3.960      0.000     -80.617     -27.117\n",
       "Total_Waste_                 -14.4252      6.041     -2.388      0.017     -26.305      -2.546\n",
       "Diesel_waste_water_           12.6611      5.962      2.123      0.034       0.935      24.387\n",
       "Flour_and_waste_oil_          16.7290      6.976      2.398      0.017       3.010      30.448\n",
       "Kitchen_waste_paste_           8.7311      2.769      3.153      0.002       3.285      14.177\n",
       "==============================================================================\n",
       "Omnibus:                       11.183   Durbin-Watson:                   2.106\n",
       "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               11.436\n",
       "Skew:                           0.430   Prob(JB):                      0.00329\n",
       "Kurtosis:                       3.125   Cond. No.                     3.38e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.26e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shenzhen_ols = ols(\"anaerobic_dailyoutput ~ Kitchen_waste_ + Fruit_and_vegetable_waste_ +\\\n",
    "       Bread_Paste_ + Total_Waste_ + Diesel_waste_water_ +\\\n",
    "       Flour_and_waste_oil_ + Kitchen_waste_paste_\", data=shenzhen_train).fit()\n",
    "shenzhen_ols_summary = shenzhen_ols.summary()\n",
    "shenzhen_ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.000916037112021\n",
      "Testing error: 0.00427342081746\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training data\n",
    "X_train = shenzhen_train[['Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
    "       'Bread_Paste_', 'Total_Waste_', 'Diesel_waste_water_',\n",
    "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_']]\n",
    "y_train = shenzhen_train.anaerobic_dailyoutput\n",
    "y_pred_train = shenzhen_ols.predict(X_train)\n",
    "\n",
    "# Compute the root-mean-square of training data\n",
    "rms_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print('Training error:',rms_train/sum(y_train))\n",
    "\n",
    "# Predict on the test data\n",
    "X_test = shenzhen_test[['Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
    "       'Bread_Paste_', 'Total_Waste_', 'Diesel_waste_water_',\n",
    "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_']]\n",
    "y_test = shenzhen_test.anaerobic_dailyoutput\n",
    "y_pred_test = shenzhen_ols.predict(X_test)\n",
    "\n",
    "# Compute the root-mean-square of test data\n",
    "rms_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print('Testing error:',rms_test/sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.52\n",
      "Accuracy of logistic regression classifier on test set: 0.00\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on train set: 1.00\n",
      "Accuracy of SVM on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('Accuracy of SVM on train set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of SVM on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyce/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of perceptron on train set: 0.05\n",
      "Accuracy of perceptron on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "# perceptron\n",
    "from sklearn.linear_model import perceptron\n",
    "net = perceptron.Perceptron(n_iter=100, verbose=0, random_state=None, fit_intercept=True, eta0=0.002)\n",
    "net.fit(X_train, y_train)\n",
    "y_pred_test = net.predict(X_test)\n",
    "print('Accuracy of perceptron on train set: {:.2f}'.format(net.score(X_train, y_train)))\n",
    "print('Accuracy of perceptron on test set: {:.2f}'.format(net.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "190  0.417582  0.392518  0.349220  0.000000  0.476419  0.401484  0.000000   \n",
      "454  0.997802  0.779097  0.728434  0.000000  0.394620  0.806168  0.427184   \n",
      "48   0.105495  0.349169  0.152932  0.430015  0.453574  0.370486  0.000000   \n",
      "21   0.046154  0.376435  0.112992  0.462175  0.500000  0.385594  0.000000   \n",
      "254  0.558242  0.485402  0.285523  0.000000  0.397568  0.458013  0.000000   \n",
      "\n",
      "       7         8         9         10        11        12       13  \n",
      "190  0.20  0.211268  0.211268  0.410256  0.429348  0.362933  0.41056  \n",
      "454  0.60  0.556338  0.000000  0.564103  0.538043  0.997483  0.53008  \n",
      "48   0.00  0.267606  0.267606  0.246154  0.201087  0.133164  0.51128  \n",
      "21   0.23  0.411972  0.492958  0.205128  0.157609  0.061790  0.55528  \n",
      "254  0.00  0.598592  0.598592  0.692308  0.673913  0.518103  0.43936  \n",
      "Accuracy of kNN on train set: 0.98\n",
      "Accuracy of kNN on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(shenzhen)\n",
    "shenzhen_normalized = pd.DataFrame(np_scaled)\n",
    "shenzhennor_train, shenzhennor_test = train_test_split(shenzhen_normalized, test_size=0.2)\n",
    "print(shenzhennor_train.head())\n",
    "Xnor_train = shenzhennor_train[[0,1,2,3,4,5,6,7]]\n",
    "ynor_train = shenzhennor_train[12]\n",
    "Xnor_test = shenzhennor_test[[0,1,2,3,4,5,6,7]]\n",
    "ynor_test = shenzhennor_test[12]\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(Xnor_train, ynor_train)\n",
    "y_pred_test = knn.predict(Xnor_test)\n",
    "print('Accuracy of kNN on train set: {:.2f}'.format(knn.score(Xnor_train, ynor_train)))\n",
    "print('Accuracy of kNN on test set: {:.2f}'.format(knn.score(Xnor_test, ynor_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGboost on train set: 0.35\n",
      "Accuracy of XGboost on test set: 0.00\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "print('Accuracy of XGboost on train set: {:.2f}'.format(xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGboost on test set: {:.2f}'.format(xgb.score(X_test, y_test)))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on train set: 0.89\n",
      "Accuracy of Random Forest on test set: 0.11\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators = 1000)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print('Accuracy of Random Forest on train set: {:.2f}'.format(random_forest.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest on test set: {:.2f}'.format(random_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion 1:For anaerobic_dailyoutput, only kNN is a good model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Toy Model Part2: Model for anaerobic_cumuprod__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>anaerobic_cumuprod</td> <th>  R-squared:         </th> <td>   0.699</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.693</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   117.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 02 Mar 2018</td>  <th>  Prob (F-statistic):</th> <td>1.06e-88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>03:51:32</td>      <th>  Log-Likelihood:    </th> <td> -5245.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   364</td>       <th>  AIC:               </th> <td>1.051e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   356</td>       <th>  BIC:               </th> <td>1.054e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     7</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td> 1.185e+06</td> <td> 7.89e+04</td> <td>   15.017</td> <td> 0.000</td> <td> 1.03e+06</td> <td> 1.34e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kitchen_waste_</th>             <td>  1.13e+04</td> <td> 1389.463</td> <td>    8.131</td> <td> 0.000</td> <td> 8564.903</td> <td>  1.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit_and_vegetable_waste_</th> <td> 2.344e+04</td> <td> 1503.772</td> <td>   15.589</td> <td> 0.000</td> <td> 2.05e+04</td> <td> 2.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bread_Paste_</th>               <td>-4.052e+04</td> <td> 2915.238</td> <td>  -13.900</td> <td> 0.000</td> <td>-4.63e+04</td> <td>-3.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total_Waste_</th>               <td>-5782.0273</td> <td> 1302.554</td> <td>   -4.439</td> <td> 0.000</td> <td>-8343.695</td> <td>-3220.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Waste_oil_</th>                 <td>-7389.6160</td> <td> 4483.558</td> <td>   -1.648</td> <td> 0.100</td> <td>-1.62e+04</td> <td> 1427.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel_waste_water_</th>        <td> 3359.6432</td> <td> 1264.034</td> <td>    2.658</td> <td> 0.008</td> <td>  873.730</td> <td> 5845.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flour_and_waste_oil_</th>       <td> -352.0207</td> <td> 1482.905</td> <td>   -0.237</td> <td> 0.812</td> <td>-3268.375</td> <td> 2564.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kitchen_waste_paste_</th>       <td> -768.3346</td> <td>  586.868</td> <td>   -1.309</td> <td> 0.191</td> <td>-1922.499</td> <td>  385.829</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.309</td> <th>  Durbin-Watson:     </th> <td>   1.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.520</td> <th>  Jarque-Bera (JB):  </th> <td>   1.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.131</td> <th>  Prob(JB):          </th> <td>   0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.080</td> <th>  Cond. No.          </th> <td>3.31e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     anaerobic_cumuprod   R-squared:                       0.699\n",
       "Model:                            OLS   Adj. R-squared:                  0.693\n",
       "Method:                 Least Squares   F-statistic:                     117.9\n",
       "Date:                Fri, 02 Mar 2018   Prob (F-statistic):           1.06e-88\n",
       "Time:                        03:51:32   Log-Likelihood:                -5245.0\n",
       "No. Observations:                 364   AIC:                         1.051e+04\n",
       "Df Residuals:                     356   BIC:                         1.054e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                   1.185e+06   7.89e+04     15.017      0.000    1.03e+06    1.34e+06\n",
       "Kitchen_waste_               1.13e+04   1389.463      8.131      0.000    8564.903     1.4e+04\n",
       "Fruit_and_vegetable_waste_  2.344e+04   1503.772     15.589      0.000    2.05e+04    2.64e+04\n",
       "Bread_Paste_               -4.052e+04   2915.238    -13.900      0.000   -4.63e+04   -3.48e+04\n",
       "Total_Waste_               -5782.0273   1302.554     -4.439      0.000   -8343.695   -3220.360\n",
       "Waste_oil_                 -7389.6160   4483.558     -1.648      0.100   -1.62e+04    1427.974\n",
       "Diesel_waste_water_         3359.6432   1264.034      2.658      0.008     873.730    5845.556\n",
       "Flour_and_waste_oil_        -352.0207   1482.905     -0.237      0.812   -3268.375    2564.334\n",
       "Kitchen_waste_paste_        -768.3346    586.868     -1.309      0.191   -1922.499     385.829\n",
       "==============================================================================\n",
       "Omnibus:                        1.309   Durbin-Watson:                   1.833\n",
       "Prob(Omnibus):                  0.520   Jarque-Bera (JB):                1.131\n",
       "Skew:                           0.131   Prob(JB):                        0.568\n",
       "Kurtosis:                       3.080   Cond. No.                     3.31e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.32e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shenzhen_ols = ols(\"anaerobic_cumuprod ~ Kitchen_waste_ + Fruit_and_vegetable_waste_ +\\\n",
    "       Bread_Paste_ + Total_Waste_ + Waste_oil_ + Diesel_waste_water_ +\\\n",
    "       Flour_and_waste_oil_ + Kitchen_waste_paste_\", data=shenzhen_train).fit()\n",
    "shenzhen_ols_summary = shenzhen_ols.summary()\n",
    "shenzhen_ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error(%): 0.000730745670411\n",
      "Testing error(%): 0.00246786740994\n"
     ]
    }
   ],
   "source": [
    "X_train = shenzhen_train[['Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
    "       'Bread_Paste_', 'Total_Waste_', 'Waste_oil_','Diesel_waste_water_',\n",
    "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_']]\n",
    "y_train = shenzhen_train.anaerobic_cumuprod\n",
    "y_pred_train = shenzhen_ols.predict(X_train)\n",
    "\n",
    "# Compute the root-mean-square of training data\n",
    "rms_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print('Training error(%):',rms_train/sum(y_train))\n",
    "\n",
    "# Predict on the test data\n",
    "X_test = shenzhen_test[['Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
    "       'Bread_Paste_', 'Total_Waste_', 'Waste_oil_','Diesel_waste_water_',\n",
    "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_']]\n",
    "y_test = shenzhen_test.anaerobic_cumuprod\n",
    "y_pred_test = shenzhen_ols.predict(X_test)\n",
    "\n",
    "# Compute the root-mean-square of test data\n",
    "rms_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print('Testing error(%):',rms_test/sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.62\n",
      "Accuracy of logistic regression classifier on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on train set: 1.00\n",
      "Accuracy of SVM on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('Accuracy of SVM on train set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of SVM on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyce/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of perceptron on train set: 0.05\n",
      "Accuracy of perceptron on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "# perceptron\n",
    "from sklearn.linear_model import perceptron\n",
    "net = perceptron.Perceptron(n_iter=100, verbose=0, random_state=None, fit_intercept=True, eta0=0.002)\n",
    "net.fit(X_train, y_train)\n",
    "y_pred_test = net.predict(X_test)\n",
    "print('Accuracy of perceptron on train set: {:.2f}'.format(net.score(X_train, y_train)))\n",
    "print('Accuracy of perceptron on test set: {:.2f}'.format(net.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "204  0.448352  0.485402  0.117001  0.000000  0.460575  0.413703  0.000000   \n",
      "14   0.030769  0.391726  0.156793  0.530475  0.000000  0.417880  0.475728   \n",
      "389  0.854945  0.550376  0.345509  0.000000  0.453943  0.525044  0.000000   \n",
      "425  0.934066  0.230107  0.000000  0.000000  0.000000  0.181534  0.427184   \n",
      "450  0.989011  0.838084  0.790497  0.000000  0.454311  0.869022  0.000000   \n",
      "\n",
      "       7         8         9         10        11        12       13  \n",
      "204  0.00  0.250000  0.250000  0.358974  0.320652  0.396475  0.82400  \n",
      "14   0.31  0.429577  0.711268  0.333333  0.293478  0.041247  0.61840  \n",
      "389  0.44  0.577465  0.577465  0.487179  0.456522  0.847768  0.60976  \n",
      "425  0.22  0.000000  0.000000  0.153846  0.103261  0.934525  0.18464  \n",
      "450  0.44  0.598592  0.000000  0.435897  0.402174  0.987325  0.58408  \n",
      "Accuracy of kNN on train set: 0.53\n",
      "Accuracy of kNN on test set: 0.44\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(shenzhen)\n",
    "shenzhen_normalized = pd.DataFrame(np_scaled)\n",
    "shenzhennor_train, shenzhennor_test = train_test_split(shenzhen_normalized, test_size=0.2)\n",
    "print(shenzhennor_train.head())\n",
    "Xnor_train = shenzhennor_train[[0,1,2,3,4,5,6,7]]\n",
    "ynor_train = shenzhennor_train[11]\n",
    "Xnor_test = shenzhennor_test[[0,1,2,3,4,5,6,7]]\n",
    "ynor_test = shenzhennor_test[11]\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=7)\n",
    "knn.fit(Xnor_train, ynor_train)\n",
    "y_pred_test = knn.predict(Xnor_test)\n",
    "print('Accuracy of kNN on train set: {:.2f}'.format(knn.score(Xnor_train, ynor_train)))\n",
    "print('Accuracy of kNN on test set: {:.2f}'.format(knn.score(Xnor_test, ynor_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGboost on train set: 0.96\n",
      "Accuracy of XGboost on test set: 0.07\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "print('Accuracy of XGboost on train set: {:.2f}'.format(xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGboost on test set: {:.2f}'.format(xgb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on train set: 0.98\n",
      "Accuracy of Random Forest on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators = 1000)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print('Accuracy of Random Forest on train set: {:.2f}'.format(random_forest.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest on test set: {:.2f}'.format(random_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion 2:For anaerobic_cumuprod, ols and randomforest are good models__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Toy Model Part3: Model for anaerobic_feed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>anaerobic_feed</td>  <th>  R-squared:         </th> <td>   0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 02 Mar 2018</td> <th>  Prob (F-statistic):</th> <td>1.55e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:55:17</td>     <th>  Log-Likelihood:    </th> <td> -1912.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   364</td>      <th>  AIC:               </th> <td>   3841.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   356</td>      <th>  BIC:               </th> <td>   3872.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   98.7135</td> <td>    8.335</td> <td>   11.844</td> <td> 0.000</td> <td>   82.322</td> <td>  115.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kitchen_waste_</th>             <td>    0.4214</td> <td>    0.147</td> <td>    2.871</td> <td> 0.004</td> <td>    0.133</td> <td>    0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fruit_and_vegetable_waste_</th> <td>    1.2232</td> <td>    0.159</td> <td>    7.700</td> <td> 0.000</td> <td>    0.911</td> <td>    1.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bread_Paste_</th>               <td>   -1.9487</td> <td>    0.308</td> <td>   -6.328</td> <td> 0.000</td> <td>   -2.554</td> <td>   -1.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total_Waste_</th>               <td>   -0.3041</td> <td>    0.138</td> <td>   -2.210</td> <td> 0.028</td> <td>   -0.575</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Waste_oil_</th>                 <td>    0.2172</td> <td>    0.474</td> <td>    0.458</td> <td> 0.647</td> <td>   -0.714</td> <td>    1.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diesel_waste_water_</th>        <td>    0.6396</td> <td>    0.134</td> <td>    4.790</td> <td> 0.000</td> <td>    0.377</td> <td>    0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Flour_and_waste_oil_</th>       <td>    0.0215</td> <td>    0.157</td> <td>    0.137</td> <td> 0.891</td> <td>   -0.287</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kitchen_waste_paste_</th>       <td>    0.2886</td> <td>    0.062</td> <td>    4.655</td> <td> 0.000</td> <td>    0.167</td> <td>    0.411</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>29.399</td> <th>  Durbin-Watson:     </th> <td>   1.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  38.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.614</td> <th>  Prob(JB):          </th> <td>4.26e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.016</td> <th>  Cond. No.          </th> <td>3.31e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         anaerobic_feed   R-squared:                       0.463\n",
       "Model:                            OLS   Adj. R-squared:                  0.453\n",
       "Method:                 Least Squares   F-statistic:                     43.89\n",
       "Date:                Fri, 02 Mar 2018   Prob (F-statistic):           1.55e-44\n",
       "Time:                        03:55:17   Log-Likelihood:                -1912.4\n",
       "No. Observations:                 364   AIC:                             3841.\n",
       "Df Residuals:                     356   BIC:                             3872.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     98.7135      8.335     11.844      0.000      82.322     115.105\n",
       "Kitchen_waste_                 0.4214      0.147      2.871      0.004       0.133       0.710\n",
       "Fruit_and_vegetable_waste_     1.2232      0.159      7.700      0.000       0.911       1.536\n",
       "Bread_Paste_                  -1.9487      0.308     -6.328      0.000      -2.554      -1.343\n",
       "Total_Waste_                  -0.3041      0.138     -2.210      0.028      -0.575      -0.034\n",
       "Waste_oil_                     0.2172      0.474      0.458      0.647      -0.714       1.149\n",
       "Diesel_waste_water_            0.6396      0.134      4.790      0.000       0.377       0.902\n",
       "Flour_and_waste_oil_           0.0215      0.157      0.137      0.891      -0.287       0.330\n",
       "Kitchen_waste_paste_           0.2886      0.062      4.655      0.000       0.167       0.411\n",
       "==============================================================================\n",
       "Omnibus:                       29.399   Durbin-Watson:                   1.991\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.546\n",
       "Skew:                           0.614   Prob(JB):                     4.26e-09\n",
       "Kurtosis:                       4.016   Cond. No.                     3.31e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.32e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shenzhen_ols = ols(\"anaerobic_feed ~ Kitchen_waste_ + Fruit_and_vegetable_waste_ +\\\n",
    "       Bread_Paste_ + Total_Waste_ + Waste_oil_ + Diesel_waste_water_ +\\\n",
    "       Flour_and_waste_oil_ + Kitchen_waste_paste_\", data=shenzhen_train).fit()\n",
    "shenzhen_ols_summary = shenzhen_ols.summary()\n",
    "shenzhen_ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error(%): 0.000835806520973\n",
      "Testing error(%): 0.00306044830339\n"
     ]
    }
   ],
   "source": [
    "X_train = shenzhen_train[['Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
    "       'Bread_Paste_', 'Total_Waste_', 'Waste_oil_','Diesel_waste_water_',\n",
    "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_']]\n",
    "y_train = shenzhen_train.anaerobic_feed\n",
    "y_pred_train = shenzhen_ols.predict(X_train)\n",
    "\n",
    "# Compute the root-mean-square of training data\n",
    "rms_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print('Training error(%):',rms_train/sum(y_train))\n",
    "\n",
    "# Predict on the test data\n",
    "X_test = shenzhen_test[['Kitchen_waste_', 'Fruit_and_vegetable_waste_',\n",
    "       'Bread_Paste_', 'Total_Waste_', 'Waste_oil_','Diesel_waste_water_',\n",
    "       'Flour_and_waste_oil_', 'Kitchen_waste_paste_']]\n",
    "y_test = shenzhen_test.anaerobic_feed\n",
    "y_pred_test = shenzhen_ols.predict(X_test)\n",
    "\n",
    "# Compute the root-mean-square of test data\n",
    "rms_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print('Testing error(%):',rms_test/sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.20\n",
      "Accuracy of logistic regression classifier on test set: 0.07\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on train set: 1.00\n",
      "Accuracy of SVM on test set: 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('Accuracy of SVM on train set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of SVM on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of perceptron on train set: 0.04\n",
      "Accuracy of perceptron on test set: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joyce/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# perceptron\n",
    "from sklearn.linear_model import perceptron\n",
    "net = perceptron.Perceptron(n_iter=100, verbose=0, random_state=None, fit_intercept=True, eta0=0.002)\n",
    "net.fit(X_train, y_train)\n",
    "y_pred_test = net.predict(X_test)\n",
    "print('Accuracy of perceptron on train set: {:.2f}'.format(net.score(X_train, y_train)))\n",
    "print('Accuracy of perceptron on test set: {:.2f}'.format(net.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "371  0.815385  0.765835  0.249740  0.000000  0.344141  0.669842  0.000000   \n",
      "90   0.197802  0.350356  0.250483  0.821746  0.483788  0.447004  0.000000   \n",
      "412  0.905495  0.657957  0.691759  0.000000  0.400516  0.700956  0.000000   \n",
      "129  0.283516  0.388064  0.481514  0.380398  0.598379  0.481241  0.000000   \n",
      "38   0.083516  0.357680  0.000000  0.514242  0.472366  0.347726  0.430097   \n",
      "\n",
      "       7         8         9         10        11        12       13  \n",
      "371  0.00  1.000000  1.000000  0.589744  0.565217  0.799871  0.52168  \n",
      "90   0.22  0.264085  0.341549  0.205128  0.157609  0.189254  0.38632  \n",
      "412  0.00  0.732394  0.732394  0.435897  0.402174  0.905671  0.56608  \n",
      "129  0.22  0.408451  0.408451  0.358974  0.380435  0.253215  0.33088  \n",
      "38   0.33  0.288732  0.560915  0.194872  0.146739  0.110081  0.63072  \n",
      "Accuracy of kNN on train set: 0.59\n",
      "Accuracy of kNN on test set: 0.45\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(shenzhen)\n",
    "shenzhen_normalized = pd.DataFrame(np_scaled)\n",
    "shenzhennor_train, shenzhennor_test = train_test_split(shenzhen_normalized, test_size=0.2)\n",
    "print(shenzhennor_train.head())\n",
    "Xnor_train = shenzhennor_train[[0,1,2,3,4,5,6,7]]\n",
    "ynor_train = shenzhennor_train[10]\n",
    "Xnor_test = shenzhennor_test[[0,1,2,3,4,5,6,7]]\n",
    "ynor_test = shenzhennor_test[10]\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=6)\n",
    "knn.fit(Xnor_train, ynor_train)\n",
    "y_pred_test = knn.predict(Xnor_test)\n",
    "print('Accuracy of kNN on train set: {:.2f}'.format(knn.score(Xnor_train, ynor_train)))\n",
    "print('Accuracy of kNN on test set: {:.2f}'.format(knn.score(Xnor_test, ynor_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGboost on train set: 0.96\n",
      "Accuracy of XGboost on test set: 0.07\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "print('Accuracy of XGboost on train set: {:.2f}'.format(xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGboost on test set: {:.2f}'.format(xgb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on train set: 0.92\n",
      "Accuracy of Random Forest on test set: 0.54\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators = 1000)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print('Accuracy of Random Forest on train set: {:.2f}'.format(random_forest.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest on test set: {:.2f}'.format(random_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion 3:For anaerobic_feed, no good models__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
