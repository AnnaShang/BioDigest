{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.ExcelFile('HainanData_kindofClean.xlsx')\n",
    "hainan = excel.parse(\"Clean\")\n",
    "hainan.columns = hainan.columns.str.replace('\\s+', '_')\n",
    "hainan.columns = hainan.columns.str.replace('(', '')\n",
    "hainan.columns = hainan.columns.str.replace(')', '')\n",
    "hainan.drop(['Day', 'Year', 'Water/m3', 'Total_electricity_cons_kWh', \n",
    "             '50%_NaOH/kg', 'FeCl2/kg', 'PAM/kg', 'Defoamer/kg', 'day_#2'], axis = 1, inplace = True)\n",
    "d = {'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6,\n",
    "     'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\n",
    "hainan.Month = hainan.Month.map(d)\n",
    "hainan.BioCNG_Produced_Nm3 = hainan.BioCNG_Produced_Nm3.shift(-15)\n",
    "hainan.drop(hainan.tail(15).index,inplace=True)\n",
    "hainan['BioCNG_cumsum'] = hainan.BioCNG_Produced_Nm3.cumsum()\n",
    "print(hainan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hainan_train, hainan_test = train_test_split(hainan, test_size=0.2)\n",
    "print('train data len:',len(hainan_train))\n",
    "print('test data len:',len(hainan_test))\n",
    "hainan\n",
    "hainan = hainan[np.isfinite(hainan['Month'])]\n",
    "print(hainan.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ols\n",
    "hainan_ols = ols(\"BioCNG_cumsum ~ Manure_input_t + Bagasse_1_input_t + Lees_fermentation +\\\n",
    "                    Fish_waste_input_t + Alcowaste_input_t + Cassava_input_t + Grass_input_t +\\\n",
    "                    Tea_waste_input_t + Other_input_t \", data=hainan_train).fit()\n",
    "hainan_ols_summary = hainan_ols.summary()\n",
    "hainan_ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Liquid_Fertilizer_Produced_t</td> <th>  R-squared:         </th> <td>   0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                         <td>OLS</td>             <th>  Adj. R-squared:    </th> <td>   0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                   <td>Least Squares</td>        <th>  F-statistic:       </th> <td>   7.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                   <td>Fri, 02 Mar 2018</td>       <th>  Prob (F-statistic):</th> <td>4.45e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                       <td>17:18:01</td>           <th>  Log-Likelihood:    </th> <td> -4408.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>            <td>   816</td>            <th>  AIC:               </th> <td>   8836.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>                <td>   806</td>            <th>  BIC:               </th> <td>   8883.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                    <td>     9</td>            <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>            <td>nonrobust</td>          <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   19.4213</td> <td>    3.606</td> <td>    5.385</td> <td> 0.000</td> <td>   12.343</td> <td>   26.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Manure_input_t</th>     <td>    0.8652</td> <td>    0.231</td> <td>    3.746</td> <td> 0.000</td> <td>    0.412</td> <td>    1.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bagasse_1_input_t</th>  <td>    0.2030</td> <td>    0.128</td> <td>    1.589</td> <td> 0.112</td> <td>   -0.048</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lees_fermentation</th>  <td>    0.3230</td> <td>    0.264</td> <td>    1.225</td> <td> 0.221</td> <td>   -0.195</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fish_waste_input_t</th> <td>    1.2228</td> <td>    0.328</td> <td>    3.725</td> <td> 0.000</td> <td>    0.579</td> <td>    1.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Alcowaste_input_t</th>  <td>    0.4469</td> <td>    0.436</td> <td>    1.025</td> <td> 0.305</td> <td>   -0.408</td> <td>    1.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cassava_input_t</th>    <td>    0.3431</td> <td>    0.070</td> <td>    4.900</td> <td> 0.000</td> <td>    0.206</td> <td>    0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grass_input_t</th>      <td>   -0.2185</td> <td>    0.249</td> <td>   -0.876</td> <td> 0.381</td> <td>   -0.708</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea_waste_input_t</th>  <td>    0.2827</td> <td>    1.012</td> <td>    0.279</td> <td> 0.780</td> <td>   -1.703</td> <td>    2.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Other_input_t</th>      <td>    0.0481</td> <td>    0.060</td> <td>    0.799</td> <td> 0.425</td> <td>   -0.070</td> <td>    0.166</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>228.341</td> <th>  Durbin-Watson:     </th> <td>   1.933</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 509.214</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.528</td>  <th>  Prob(JB):          </th> <td>2.66e-111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.373</td>  <th>  Cond. No.          </th> <td>    98.3</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                 \n",
       "========================================================================================\n",
       "Dep. Variable:     Liquid_Fertilizer_Produced_t   R-squared:                       0.080\n",
       "Model:                                      OLS   Adj. R-squared:                  0.070\n",
       "Method:                           Least Squares   F-statistic:                     7.802\n",
       "Date:                          Fri, 02 Mar 2018   Prob (F-statistic):           4.45e-11\n",
       "Time:                                  17:18:01   Log-Likelihood:                -4408.2\n",
       "No. Observations:                           816   AIC:                             8836.\n",
       "Df Residuals:                               806   BIC:                             8883.\n",
       "Df Model:                                     9                                         \n",
       "Covariance Type:                      nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             19.4213      3.606      5.385      0.000      12.343      26.500\n",
       "Manure_input_t         0.8652      0.231      3.746      0.000       0.412       1.319\n",
       "Bagasse_1_input_t      0.2030      0.128      1.589      0.112      -0.048       0.454\n",
       "Lees_fermentation      0.3230      0.264      1.225      0.221      -0.195       0.841\n",
       "Fish_waste_input_t     1.2228      0.328      3.725      0.000       0.579       1.867\n",
       "Alcowaste_input_t      0.4469      0.436      1.025      0.305      -0.408       1.302\n",
       "Cassava_input_t        0.3431      0.070      4.900      0.000       0.206       0.481\n",
       "Grass_input_t         -0.2185      0.249     -0.876      0.381      -0.708       0.271\n",
       "Tea_waste_input_t      0.2827      1.012      0.279      0.780      -1.703       2.269\n",
       "Other_input_t          0.0481      0.060      0.799      0.425      -0.070       0.166\n",
       "==============================================================================\n",
       "Omnibus:                      228.341   Durbin-Watson:                   1.933\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              509.214\n",
       "Skew:                           1.528   Prob(JB):                    2.66e-111\n",
       "Kurtosis:                       5.373   Cond. No.                         98.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ols\n",
    "hainan_ols = ols(\"Liquid_Fertilizer_Produced_t ~ Manure_input_t + Bagasse_1_input_t + Lees_fermentation +\\\n",
    "                    Fish_waste_input_t + Alcowaste_input_t + Cassava_input_t + Grass_input_t +\\\n",
    "                    Tea_waste_input_t + Other_input_t \", data=hainan_train).fit()\n",
    "hainan_ols_summary = hainan_ols.summary()\n",
    "hainan_ols_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Solid_fertilizer_produced_t</td> <th>  R-squared:         </th> <td>   0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                        <td>OLS</td>             <th>  Adj. R-squared:    </th> <td>   0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>Least Squares</td>        <th>  F-statistic:       </th> <td>   6.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                  <td>Fri, 02 Mar 2018</td>       <th>  Prob (F-statistic):</th> <td>3.06e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                      <td>17:18:06</td>           <th>  Log-Likelihood:    </th> <td> -3256.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>           <td>   816</td>            <th>  AIC:               </th> <td>   6533.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>               <td>   806</td>            <th>  BIC:               </th> <td>   6580.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                   <td>     9</td>            <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>           <td>nonrobust</td>          <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    1.1935</td> <td>    0.879</td> <td>    1.357</td> <td> 0.175</td> <td>   -0.533</td> <td>    2.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Manure_input_t</th>     <td>   -0.0037</td> <td>    0.056</td> <td>   -0.065</td> <td> 0.948</td> <td>   -0.114</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bagasse_1_input_t</th>  <td>    0.1481</td> <td>    0.031</td> <td>    4.753</td> <td> 0.000</td> <td>    0.087</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lees_fermentation</th>  <td>    0.1414</td> <td>    0.064</td> <td>    2.200</td> <td> 0.028</td> <td>    0.015</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fish_waste_input_t</th> <td>    0.2272</td> <td>    0.080</td> <td>    2.839</td> <td> 0.005</td> <td>    0.070</td> <td>    0.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Alcowaste_input_t</th>  <td>   -0.1410</td> <td>    0.106</td> <td>   -1.327</td> <td> 0.185</td> <td>   -0.350</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cassava_input_t</th>    <td>    0.0305</td> <td>    0.017</td> <td>    1.789</td> <td> 0.074</td> <td>   -0.003</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grass_input_t</th>      <td>   -0.0156</td> <td>    0.061</td> <td>   -0.256</td> <td> 0.798</td> <td>   -0.135</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tea_waste_input_t</th>  <td>    0.1629</td> <td>    0.247</td> <td>    0.660</td> <td> 0.509</td> <td>   -0.321</td> <td>    0.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Other_input_t</th>      <td>    0.0567</td> <td>    0.015</td> <td>    3.858</td> <td> 0.000</td> <td>    0.028</td> <td>    0.086</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>691.254</td> <th>  Durbin-Watson:     </th> <td>   2.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>14827.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.860</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>22.403</td>  <th>  Cond. No.          </th> <td>    98.3</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:     Solid_fertilizer_produced_t   R-squared:                       0.069\n",
       "Model:                                     OLS   Adj. R-squared:                  0.059\n",
       "Method:                          Least Squares   F-statistic:                     6.669\n",
       "Date:                         Fri, 02 Mar 2018   Prob (F-statistic):           3.06e-09\n",
       "Time:                                 17:18:06   Log-Likelihood:                -3256.6\n",
       "No. Observations:                          816   AIC:                             6533.\n",
       "Df Residuals:                              806   BIC:                             6580.\n",
       "Df Model:                                    9                                         \n",
       "Covariance Type:                     nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              1.1935      0.879      1.357      0.175      -0.533       2.920\n",
       "Manure_input_t        -0.0037      0.056     -0.065      0.948      -0.114       0.107\n",
       "Bagasse_1_input_t      0.1481      0.031      4.753      0.000       0.087       0.209\n",
       "Lees_fermentation      0.1414      0.064      2.200      0.028       0.015       0.268\n",
       "Fish_waste_input_t     0.2272      0.080      2.839      0.005       0.070       0.384\n",
       "Alcowaste_input_t     -0.1410      0.106     -1.327      0.185      -0.350       0.068\n",
       "Cassava_input_t        0.0305      0.017      1.789      0.074      -0.003       0.064\n",
       "Grass_input_t         -0.0156      0.061     -0.256      0.798      -0.135       0.104\n",
       "Tea_waste_input_t      0.1629      0.247      0.660      0.509      -0.321       0.647\n",
       "Other_input_t          0.0567      0.015      3.858      0.000       0.028       0.086\n",
       "==============================================================================\n",
       "Omnibus:                      691.254   Durbin-Watson:                   2.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14827.134\n",
       "Skew:                           3.860   Prob(JB):                         0.00\n",
       "Kurtosis:                      22.403   Cond. No.                         98.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ols\n",
    "hainan_ols = ols(\"Solid_fertilizer_produced_t ~ Manure_input_t + Bagasse_1_input_t + Lees_fermentation +\\\n",
    "                    Fish_waste_input_t + Alcowaste_input_t + Cassava_input_t + Grass_input_t +\\\n",
    "                    Tea_waste_input_t + Other_input_t \", data=hainan_train).fit()\n",
    "hainan_ols_summary = hainan_ols.summary()\n",
    "hainan_ols_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ols results based on three different dependent variable, we decided to focus on the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.00147106480219\n",
      "Testing error: 0.00577617250521\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training data\n",
    "X_train = hainan_train[['Manure_input_t', 'Bagasse_1_input_t',\n",
    "       'Lees_fermentation', 'Fish_waste_input_t', 'Alcowaste_input_t',\n",
    "       'Cassava_input_t', 'Grass_input_t', 'Tea_waste_input_t',\n",
    "       'Other_input_t']]\n",
    "y_train = hainan_train.BioCNG_Produced_Nm3\n",
    "y_pred_train = hainan_ols.predict(X_train)\n",
    "\n",
    "# Compute the root-mean-square of training data\n",
    "rms_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print('Training error:',rms_train/sum(y_train))\n",
    "\n",
    "# Predict on the test data\n",
    "X_test = hainan_test[['Manure_input_t', 'Bagasse_1_input_t',\n",
    "       'Lees_fermentation', 'Fish_waste_input_t', 'Alcowaste_input_t',\n",
    "       'Cassava_input_t', 'Grass_input_t', 'Tea_waste_input_t',\n",
    "       'Other_input_t']]\n",
    "y_test = hainan_test.BioCNG_Produced_Nm3\n",
    "y_pred_test = hainan_ols.predict(X_test)\n",
    "\n",
    "# Compute the root-mean-square of test data\n",
    "rms_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print('Testing error:',rms_test/sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on train set: 0.17\n",
      "Accuracy of logistic regression classifier on test set: 0.01\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_test = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on train set: 0.70\n",
      "Accuracy of SVM on test set: 0.01\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)  \n",
    "y_pred_test = clf.predict(X_test)\n",
    "print('Accuracy of SVM on train set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of SVM on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of perceptron on train set: 0.02\n",
      "Accuracy of perceptron on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "# perceptron\n",
    "from sklearn.linear_model import perceptron\n",
    "net = perceptron.Perceptron(n_iter=100, verbose=0, random_state=None, fit_intercept=True, eta0=0.002)\n",
    "net.fit(X_train, y_train)\n",
    "y_pred_test = net.predict(X_test)\n",
    "print('Accuracy of perceptron on train set: {:.2f}'.format(net.score(X_train, y_train)))\n",
    "print('Accuracy of perceptron on test set: {:.2f}'.format(net.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "230  1.000000  0.212121  0.225711  0.000000  0.343670  0.251059  0.187443   \n",
      "774  0.454545  0.757576  0.761531  0.158389  0.303670  0.000000  0.000000   \n",
      "113  0.636364  0.090909  0.110893  0.000000  0.187566  0.231579  0.000000   \n",
      "999  0.000000  0.969697  0.982336  0.480884  0.696404  0.472051  0.701773   \n",
      "753  0.363636  0.727273  0.738960  0.209916  0.188165  0.000000  0.000000   \n",
      "\n",
      "           7         8         9     ...      12        13       14   15  \\\n",
      "230  0.187443  0.075319  0.075319    ...     0.0  0.000000  0.00000  0.0   \n",
      "774  0.000000  0.502068  0.502068    ...     0.0  0.288945  0.00000  0.0   \n",
      "113  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.00000  0.0   \n",
      "999  0.701773  0.000000  0.000000    ...     0.0  0.000000  0.14898  0.0   \n",
      "753  0.000000  0.497242  0.497242    ...     0.0  0.000000  0.00000  0.0   \n",
      "\n",
      "           16   17        18        19        20        21  \n",
      "230  0.000000  0.0  0.000000  0.107467  0.384615  0.146368  \n",
      "774  0.000000  0.0  0.000000  0.062685  0.153846  0.718202  \n",
      "113  0.000000  0.0  0.000000  0.089758  0.184615  0.071592  \n",
      "999  0.495457  0.0  0.000000  0.190772  0.000000  0.957861  \n",
      "753  0.000000  0.0  0.135259  0.140629  0.000000  0.699781  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Accuracy of kNN on train set: 0.67\n",
      "Accuracy of kNN on test set: 0.46\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(hainan)\n",
    "hainan_normalized = pd.DataFrame(np_scaled)\n",
    "hainan_normalized_train, hainan_normalized_test = train_test_split(hainan_normalized, test_size=0.2)\n",
    "print(hainan_normalized_train.head())\n",
    "\n",
    "Xnor_train = hainan_normalized_train[[10,11,12,13,14,15,16,17,18]]\n",
    "ynor_train = hainan_normalized_train[21]\n",
    "Xnor_test = hainan_normalized_test[[10,11,12,13,14,15,16,17,18]]\n",
    "ynor_test = hainan_normalized_test[21]\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(Xnor_train, ynor_train)\n",
    "y_pred_test = knn.predict(Xnor_test)\n",
    "print('Accuracy of kNN on train set: {:.2f}'.format(knn.score(Xnor_train, ynor_train)))\n",
    "print('Accuracy of kNN on test set: {:.2f}'.format(knn.score(Xnor_test, ynor_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on train set: 0.86\n",
      "Accuracy of Random Forest on test set: 0.45\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(n_estimators = 1000)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print('Accuracy of Random Forest on train set: {:.2f}'.format(random_forest.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest on test set: {:.2f}'.format(random_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "print('Accuracy of XGboost on train set: {:.2f}'.format(xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGboost on test set: {:.2f}'.format(xgb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
